---
layout: talk
title: " Skin Cancer Detection with ViTs"
type: "Projects"
author_profile: true
permalink: /projects/2024-10-01-project-1
venue: "Goettingen"
date: 2024-10-01
location: "Goettingen, Germany"
---
Vision Transformers (ViTs) leverage the Transformer architecture, originally designed for natural language processing, to process visual data. Unlike traditional Convolutional Neural Networks (CNNs), ViTs treat image patches as sequences, enabling the model to capture global context through self-attention mechanisms. This approach has demonstrated superior performance in tasks like image classification and segmentation, challenging the dominance of CNNs in computer vision by offering a more scalable and versatile framework for visual data analysis.
![ViT](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F5143577%2F848ff6c2cbc5398dd3456b42f780a9ae%2FScreen_Shot_2021-01-26_at_9.43.31_PM_uI4jjMq.png?generation=1723646566335310&alt=media)
In this project, I trained different ViTs to classify skin cancer images using data from the ISIC 2024 Challenge, hosted on Kaggle. This competition focuses on detecting skin cancer from high-resolution 3D Total Body Photography (3D-TBP) images. Participants' models are evaluated on multiple metrics, including the hidden Kaggle score (based on partial AUC at high true positive rates) and top-15 retrieval sensitivity, which measures the modelâ€™s ability to prioritize high-risk lesions. I compared my ViTs based on both their Kaggle scores and the best accuracy achieved on the validation data


![result](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F5143577%2Fa7cdd9232bd9a21ba341cf50496d3c8c%2Fdownload%20(1).png?generation=1723649425473443&alt=media)

| Model                                     |real score |  Is it Ploto? | Best Acc | Number of Epochs |Number of para|paper|
|-------------------------------------------|----------|----------|--------------|------------------|------------------|------------------|
| Simple ViT                               | 101|  yes      | 92           | 50               | 53533698 | https://arxiv.org/abs/2205.01580 |
| **CaiT**                                   | 97   | yes    | 93           | 10               | 120801282 |https://arxiv.org/abs/2103.17239 |
|**Vision Transformer for Small Datasets**   | 132 | yes      | 92           | 50               | 54528520 |https://arxiv.org/abs/2112.13492 |
|**Token to Token ViT**                    |113 | out of memory       | 92           | 50               | 19801116 |https://arxiv.org/abs/2101.11986 |
|LeViT                    |125        | yes       | 94           | 100               | 17348972 |https://arxiv.org/abs/2104.01136 |
|  ats ViT                 |113     | yes      | 92           | 25               | 52463080 |https://arxiv.org/abs/2111.15667 |
|**xcit**                     |122        | yes      |      92      | 25               | 122141864 |https://arxiv.org/abs/2106.09681 |
|vit_with_patch_merger                    |118        |yes| 92                 | 25          | 77687272 |https://arxiv.org/abs/2202.12015 |
